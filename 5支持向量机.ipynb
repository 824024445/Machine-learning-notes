{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5支持向量机.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "R50gbgr2WSQL",
        "c32uhyKhZomk",
        "zDMTonF-gjKA"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/824024445/Machine-learning-notes/blob/master/5%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1982NKSXgUsc",
        "colab_type": "text"
      },
      "source": [
        "也叫最大间隔分类\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CAl8RulkTgp",
        "colab_type": "text"
      },
      "source": [
        "# 一、线性支持向量机分类\n",
        "以鸢尾花数据为例  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lryTPbMntkoA",
        "colab_type": "text"
      },
      "source": [
        "硬间隔，软间隔：\n",
        "软间隔就是允许一部分数据在边界内  \n",
        "参数解释：\n",
        "C：值越小间隔越“软”\n",
        "loss:计算软间隔用的损失函数的类型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z-xHozuScc9",
        "colab_type": "text"
      },
      "source": [
        "与逻辑回归分类器比较：\n",
        "- 逻辑回归分类器是判断属于每个类别的概率，选择最大的那个\n",
        "- 损失函数的判别项不一样。逻辑回归分类器每个项都有损失。而支持向量机有一个阈值，小于这个阈值则损失为0.\n",
        "\n",
        "> 注：SVM为：Support Vector Machines支持向量机。  而SVC是Support Vector Classification支持向量分类"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oGsiXzEq9LG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "599fc94f-cbe0-4562-db31-0027b6b07a68"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler # 特征缩放。特征缩放后的边界会更好\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris[\"data\"][:, (2,3)] # 只选取长度和宽度两列\n",
        "y = (iris[\"target\"]==2).astype(np.int) # 只判断目标是否为Virginica这种花\n",
        "\n",
        "svm_clf = Pipeline([\n",
        "  (\"scaler\",StandardScaler()),\n",
        "  (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\"))\n",
        "])\n",
        "\n",
        "svm_clf.fit(X, y)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('linear_svc',\n",
              "                 LinearSVC(C=1, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='hinge', max_iter=1000, multi_class='ovr',\n",
              "                           penalty='l2', random_state=None, tol=0.0001,\n",
              "                           verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhPxkJudR3R2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f86ab236-e8d2-4cae-e06a-738af0e465eb"
      },
      "source": [
        "svm_clf.predict([[5.5, 1.7]])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5zWhCshkV1c",
        "colab_type": "text"
      },
      "source": [
        "# 二、非线性支持向量机分类"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R50gbgr2WSQL",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 方式1：转换数据集添加多项式特征"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXaN5YV_UI9z",
        "colab_type": "text"
      },
      "source": [
        "有些数据不是线性的，所以[**同多项式回归**](https://github.com/824024445/Machine-learning-notes/blob/master/4%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B.ipynb)。要对数据集通过PolyolynomialFeaturenomialFeature进行转换，增加特征"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwCdiKeLUjEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3e050592-49d3-4e1f-bce0-a923ccbcf036"
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "polynomial_svm_clf = Pipeline((\n",
        "    (\"poly_features\", PolynomialFeatures(degree=3)),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\"))\n",
        "))\n",
        "\n",
        "polynomial_svm_clf.fit(X, y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('poly_features',\n",
              "                 PolynomialFeatures(degree=3, include_bias=True,\n",
              "                                    interaction_only=False, order='C')),\n",
              "                ('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svm_clf',\n",
              "                 LinearSVC(C=10, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='hinge', max_iter=1000, multi_class='ovr',\n",
              "                           penalty='l2', random_state=None, tol=0.0001,\n",
              "                           verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTNL7kjXWYdd",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 方式2：核函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB6pguEPhp_F",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.1 核函数概要"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD5bHHtKaQGU",
        "colab_type": "text"
      },
      "source": [
        "> 具体解析见《机器学习》（西瓜书）--周志华 6.3节 核函数 \n",
        "\n",
        "在数据并不是线性可分的情况下。可以将样本从原始空间映射到一个更高维的特征空间，使样本在新的特征空间线性可分。  \n",
        "核函数即为将原样本映射为新样本的函数。  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "常用核函数：\n",
        "![替代文字](https://raw.githubusercontent.com/824024445/Machine-learning-notes/master/img/5-1.jpg)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "常用的核函数的适用情况：\n",
        "- 线性核:主要用于线性可分的情况。我们可以看到特征空间到输入空间的维度是一样的，其参数少|速度快。对于线性可分数据，其分类效果很理想，因此我们通常首先尝试用线性核函数来做分类，看看效果如何，如果不行再换别的。\n",
        "- 多项式核：多项式核函数可以实现将低维的输入空间映射到高纬的特征空间，但是多项式核函数的参数多，当多项式的阶数比较高的时候，核矩阵的元素值将趋于无穷大或者无穷小，计算复杂度会大到无法计算。\n",
        "- 高斯核：高斯径向基函数是一种局部性强的核函数，其可以将一个样本映射到一个更高维的空间内，该核函数是应用最广的一个，无论大样本还是小样本都有比较好的性能，而且其相对于多项式核函数参数要少，因此大多数情况下在不知道用什么核函数的时候，优先使用高斯核函数。\n",
        "- 拉普拉斯核\n",
        "- Sigmoid核：采用sigmoid核函数，支持向量机实现的就是一种多层神经网络。\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**实践中核函数的选取依据：**  \n",
        "因此，在选用核函数的时候，如果我们对我们的数据有一定的先验知识，就利用先验来选择符合数据分布的核函数；如果不知道的话，通常使用交叉验证1的方法，来试用不同的核函数，误差最小的即为效果最好的核函数，或者也可以将多个核函数结合起来，形成混合核函数。在吴恩达的课上，也曾经给出过一系列的选择核函数的方法：\n",
        "- 如果特征的数量大到和样本数量差不多，则选用LR或者线性核的SVM；\n",
        "- 如果特征的数量小，样本的数量正常，则选用SVM+高斯核函数；\n",
        "- 如果特征的数量小，而样本的数量很大，则需要手工添加一些特征从而变成第一种情况。\n",
        "- 注：其实最完美的就是高斯核函数，如果想要快，用线性。\n",
        "\n",
        "> 本人想法：感觉如果将核方法设定为“poly”，那么就跟添加多项式特征的方法一样了。那么为什么又说性能比单纯的添加多项式特征好呢？应该是其它的几种核函数，poly核函数本身跟直接添加多项式特征一样。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c32uhyKhZomk",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.2 多项式核\n",
        "由于添加多项式特征在特征多时会产生大量的新特征，运行速度会变得很慢。  \n",
        "可以理解成，不用往数据集中添加大量新特征，却能够得到同样好的结果，的一种数学方法。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTzt9lyUX4BU",
        "colab_type": "text"
      },
      "source": [
        "参数解释：\n",
        "- kernel：在算法中使用的内核类型。它必须是'linear'，'poly'，'rbf'，'sigmoid'，'precomputed'或者callable之一\n",
        "- degree:多项式核函数的次数（'poly'）。被所有其他内核忽略。同PolynomialFeatures类，指定的是多项式的阶数\n",
        "\n",
        "- coef0：核函数中的独立项。它只在'poly'和'sigmoid'中很重要。控制高阶多项式和低阶多项式对模型的影响\n",
        "- C：错误术语的惩罚参数C，默认为1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0Xzy07eXeMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cdabd50f-3bfc-4e6b-9177-3961685c760e"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "poly_kernel_svm_clf = Pipeline((\n",
        " # 不用使用PolynomialFeatures给数据集添加新特征了\n",
        " (\"scaler\", StandardScaler()),\n",
        " (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
        " ))\n",
        "poly_kernel_svm_clf.fit(X, y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svm_clf',\n",
              "                 SVC(C=5, cache_size=200, class_weight=None, coef0=1,\n",
              "                     decision_function_shape='ovr', degree=3,\n",
              "                     gamma='auto_deprecated', kernel='poly', max_iter=-1,\n",
              "                     probability=False, random_state=None, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDMTonF-gjKA",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.3 高斯核（rbf核）(默认项）\n",
        "使用相似函数（高斯径向基函数），增加相似特征。  \n",
        "它适用于特征少，数据量正常的情况下，因此是SVC类该项参数的默认值"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRgphNV3jjzQ",
        "colab_type": "text"
      },
      "source": [
        "参数：\n",
        "gamma：值越大，拟合程度越高\n",
        "C：同样，值越大，拟合程度越高"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMaiqWBMimxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c5a915a7-ae7f-48cb-c0f9-a6049bbee912"
      },
      "source": [
        "rbf_kernel_svm_clf = Pipeline((\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.01))\n",
        "))\n",
        "\n",
        "rbf_kernel_svm_clf.fit(X, y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svm_clf',\n",
              "                 SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
              "                     decision_function_shape='ovr', degree=3, gamma=5,\n",
              "                     kernel='rbf', max_iter=-1, probability=False,\n",
              "                     random_state=None, shrinking=True, tol=0.001,\n",
              "                     verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfMofxlxkbmB",
        "colab_type": "text"
      },
      "source": [
        "# 三、SVM回归"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDO5835VYimd",
        "colab_type": "text"
      },
      "source": [
        "不同于SVM分类试图找到两个类别间尽可能大的“街道”，SVM回归试图让尽可能多的样本进入街道。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE54Ncoebggj",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 线性SVM回归"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5Ju3UkcgNXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "9da404d3-61b1-4a80-beb5-f509fda14f11"
      },
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "svm_reg = LinearSVR(epsilon=0.5)\n",
        "svm_reg.fit(X, y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVR(C=1.0, dual=True, epsilon=0.5, fit_intercept=True,\n",
              "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
              "          random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mJ4EtmTcEmh",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 非线性SVM回归\n",
        "同非线性SVM分类，使用核函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7rqfPbScOVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "8dee871f-3f82-4e18-c786-5e7daf3ab93a"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1)\n",
        "svm_poly_reg.fit(X, y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=100, cache_size=200, coef0=0.0, degree=2, epsilon=0.1,\n",
              "    gamma='auto_deprecated', kernel='poly', max_iter=-1, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}